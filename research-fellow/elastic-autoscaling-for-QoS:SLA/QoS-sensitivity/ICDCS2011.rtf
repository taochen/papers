{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf230
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\fs24 \cf0 The paper using queuing theory to model performance (SLA) and cpu %. which can be used to partition the resource to each tier.  it also apply ARMA (offline) and PI control for dynamic modelling (on application level).  It eventually form a function then sort the minimum value of that function to get cpu for each tier (on container level).  \
\
good\
the concept of partitioning budget to different tier could be applied to different services.\
\
bad\
it does not seems like considering any interference between tiers, and only focus on cpu to enable minimum RTT on each tier, as for app tier and db tier all consume cpu and may influence each other.\
\
one argument from the paper is: for single tier application, determine the demand for SLA is really straightforward, which i can not agree as it miss the interference amongst services, if from coast grained then that statement is right, but wrong from fine grained.}