{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\fs24 \cf0 This is an interesting paper describe an approach for scaling cloud resource considering both SLA (which they refer to as benefits) and cost (both transition and infrastructure). They use offline machine learning and queue network to link resource and response time, and then ARMA is used to predict the total interval (transition time + stable time), the benefits is related to stable time ( total interval - transition time) and they try to find out a strategy that max arg benefits/costs.\
\
(it also rely on predicted workload, which it has not verify)\
\
This is a very typical approach based on offline QoS model and use greedy algorithm to find a proper adaptation strategy.\
\
it does not cope with QoS interferences, (neither VM not service), no which and when, the machine learning is using linear regression and it is offline. No multiple objectives and thus no conflict analysis. The greedy optimisation algorithm work only a couple of strategies (5 in the paper)  }