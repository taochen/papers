{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
The paper presents an approach based on ML to reduce the search space.\
\
But, it is very strange that the space is not used direct for search, instead, it use ML model to predict a set sub (of course, emmurating all solutions), which would then be used to do verification, based on which another exhaustive search can be made.\
\
So, the key is to reduce the time required for verification rather than the time required for the reasoning/search.\
\
\
\
Bad\
\
Only 4096 decisions is not considered as large\
\
If the ML model can cheaply predict, why not directly using it for decision making?}