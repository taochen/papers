{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 This is a very typical work that based on optimal experimental design, where the sampling has the purpose of impvroving the accuracy of performance model. The key is merely the ensemble model.\
\
In cold starts, it only random divid the samples into k sets, then an ensemble of models are built, some configurations are predicted then the ones with the highest standard deviation are selected to retrain the  ensemble\
\
In warm starts (assuming commit/code change), it uses weighted k mean clustering based on option importance to divide the training sample, and then follow the same way as before. The prediction for calculating uncertainty uses the ones from the updated systems. Then the old and new samples are merged to train the ensemble.\
\
It is a bit naive but also model agnostic.}