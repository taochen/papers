{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 The papers seems to produce a very simple method that exhaustively find the best source environment that act as a source in transfer learning.\
\
LR transfer - source model + a transfer model that inputs source perf and output target perf\
GP transfer - build a kernel based on GP covariance of the inputs/output relatedness between source and target, the kernel + source data is then used to train the target model,\
\
Bad\
\
Indeed, it says to avoid large sampling, a small set (given parameter) may be done, but still, the space of environment needs to be fully explored.\
\
Then the transferred model is used as the fitness to find best configuration, which is again exhaustive search.}