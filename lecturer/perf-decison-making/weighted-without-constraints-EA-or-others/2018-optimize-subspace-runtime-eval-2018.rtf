{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 The paper proposes a very interesting yet questionable approach to optimise SAS, it has the following stages:\
\
1. An ANOVA process to identify which control features influence the quality attribute the most, and this is done as part wise to identify information relevance and redundancy.\
2. Based on 1, the control features is splitted from the most relevant ones to least relevant one, and they are considered separately in different, sequential optimisation process, thus reducing the search space into smaller ones. (use exact algorithm)\
3. The most interesting is the function evaluation, where it relies on simulation, but this simulation is test at real deployment runtime, the claim is that when evaluate, it only affect a small part of the SAS, and incrementally increase the number of users that are affected - it stops when the solution is too bad such as a threshold is hit.\
\
bad,\
\
How large is the search space can be? Is it realistic to assume that every SAS can be run in a way that an evaluation only affect a small part of the users?\
\
How to determine how many splits (sub space) need? in the paper this seems to be manually specified.\
\
no constraint/dependency.\
\
This bing question to variable splitting for EA: do we do this in one run or consider it as different runs?\
\
}